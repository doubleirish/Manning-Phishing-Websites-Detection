{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to start the modeling process. But first let's import all the dependencies we would need and load up the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow on Python 3.x and Windows 10 needed the latest MS Visual C++ lib installed\n",
      "https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads\n"
     ]
    }
   ],
   "source": [
    "# Neural network & imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "import keras \n",
    "\n",
    "# Filter the uneccesary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print (\"tensorflow on Python 3.x and Windows 10 needed the latest MS Visual C++ lib installed\")\n",
    "print(\"https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fix the random seed\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 265320\n",
      "X_test 265320\n"
     ]
    }
   ],
   "source": [
    "# Load the numpy arrays which will be our datasets from now\n",
    "X_train, y_train = np.load(\"X_train.npy\", allow_pickle=True), np.load(\"y_train.npy\", allow_pickle=True)\n",
    "X_test, y_test = np.load(\"X_test.npy\", allow_pickle=True), np.load(\"y_test.npy\", allow_pickle=True)\n",
    "print (\"X_train\", X_train.size)\n",
    "print (\"X_test\", X_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the keras model\n",
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "from keras.utils import plot_model \n",
    "\n",
    "def get_training_model(cols):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(40, activation=\"relu\",kernel_initializer=\"uniform\",input_dim=cols)) # modified from sayaks solution\n",
    "    model.add(Dense(30, activation=\"relu\",kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1,  activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_training_model(X_train.shape[1])\n",
    "\n",
    "# plot needed vc++ lib ,  pydot library ,  and Graphviz executable in PATH\n",
    "keras.utils.plot_model(\n",
    "    model, to_file='model.png', show_shapes=True, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=False, dpi=96\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train: 0.0\n",
      "Epoch 1/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0269 - accuracy: 0.9879\n",
      "Epoch 2/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0279 - accuracy: 0.9870\n",
      "Epoch 3/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0265 - accuracy: 0.9877\n",
      "Epoch 4/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0259 - accuracy: 0.9865\n",
      "Epoch 5/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0260 - accuracy: 0.9869\n",
      "Epoch 6/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0277 - accuracy: 0.9855\n",
      "Epoch 7/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0272 - accuracy: 0.9880\n",
      "Epoch 8/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0266 - accuracy: 0.9874\n",
      "Epoch 9/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0275 - accuracy: 0.9872\n",
      "Epoch 10/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0255 - accuracy: 0.9872\n",
      "Epoch 11/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0269 - accuracy: 0.9870\n",
      "Epoch 12/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0269 - accuracy: 0.9874\n",
      "Epoch 13/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0271 - accuracy: 0.9863\n",
      "Epoch 14/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0271 - accuracy: 0.9876\n",
      "Epoch 15/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0284 - accuracy: 0.9860\n",
      "Epoch 16/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0268 - accuracy: 0.9870\n",
      "Epoch 17/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0270 - accuracy: 0.9870\n",
      "Epoch 18/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0292 - accuracy: 0.9867\n",
      "Epoch 19/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0259 - accuracy: 0.9880\n",
      "Epoch 20/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0264 - accuracy: 0.9873\n",
      "Epoch 21/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0261 - accuracy: 0.9872\n",
      "Epoch 22/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0273 - accuracy: 0.9880\n",
      "Epoch 23/128\n",
      "8844/8844 [==============================] - 0s 14us/step - loss: 0.0284 - accuracy: 0.9871\n",
      "Epoch 24/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0271 - accuracy: 0.9884\n",
      "Epoch 25/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0269 - accuracy: 0.9879\n",
      "Epoch 26/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0279 - accuracy: 0.9854\n",
      "Epoch 27/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0291 - accuracy: 0.9861\n",
      "Epoch 28/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0265 - accuracy: 0.9873\n",
      "Epoch 29/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0260 - accuracy: 0.9854\n",
      "Epoch 30/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0271 - accuracy: 0.9868\n",
      "Epoch 31/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0280 - accuracy: 0.9864\n",
      "Epoch 32/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0280 - accuracy: 0.9865\n",
      "Epoch 33/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0267 - accuracy: 0.9868\n",
      "Epoch 34/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0300 - accuracy: 0.9862\n",
      "Epoch 35/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0259 - accuracy: 0.9867\n",
      "Epoch 36/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0270 - accuracy: 0.9859\n",
      "Epoch 37/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0262 - accuracy: 0.9874\n",
      "Epoch 38/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0277 - accuracy: 0.9869\n",
      "Epoch 39/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0273 - accuracy: 0.9865\n",
      "Epoch 40/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0260 - accuracy: 0.9871\n",
      "Epoch 41/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0277 - accuracy: 0.9870\n",
      "Epoch 42/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0272 - accuracy: 0.9867\n",
      "Epoch 43/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0288 - accuracy: 0.9873\n",
      "Epoch 44/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0271 - accuracy: 0.9870\n",
      "Epoch 45/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0285 - accuracy: 0.9868\n",
      "Epoch 46/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0277 - accuracy: 0.9856\n",
      "Epoch 47/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0261 - accuracy: 0.9878\n",
      "Epoch 48/128\n",
      "8844/8844 [==============================] - 0s 18us/step - loss: 0.0267 - accuracy: 0.9867\n",
      "Epoch 49/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0261 - accuracy: 0.9874\n",
      "Epoch 50/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0265 - accuracy: 0.9868\n",
      "Epoch 51/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0268 - accuracy: 0.9850\n",
      "Epoch 52/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0265 - accuracy: 0.9871\n",
      "Epoch 53/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0274 - accuracy: 0.9867\n",
      "Epoch 54/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0266 - accuracy: 0.9869\n",
      "Epoch 55/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0276 - accuracy: 0.9867\n",
      "Epoch 56/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0257 - accuracy: 0.9882\n",
      "Epoch 57/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0267 - accuracy: 0.9869\n",
      "Epoch 58/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0299 - accuracy: 0.9852\n",
      "Epoch 59/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0259 - accuracy: 0.9874\n",
      "Epoch 60/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0286 - accuracy: 0.9867\n",
      "Epoch 61/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0278 - accuracy: 0.9865\n",
      "Epoch 62/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0259 - accuracy: 0.9877\n",
      "Epoch 63/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0270 - accuracy: 0.9868\n",
      "Epoch 64/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0259 - accuracy: 0.9874\n",
      "Epoch 65/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0279 - accuracy: 0.9864\n",
      "Epoch 66/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0259 - accuracy: 0.9876\n",
      "Epoch 67/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0272 - accuracy: 0.9873\n",
      "Epoch 68/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0269 - accuracy: 0.9869\n",
      "Epoch 69/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0264 - accuracy: 0.9872\n",
      "Epoch 70/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0283 - accuracy: 0.9861\n",
      "Epoch 71/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0267 - accuracy: 0.9876\n",
      "Epoch 72/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0271 - accuracy: 0.9865\n",
      "Epoch 73/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0255 - accuracy: 0.9878\n",
      "Epoch 74/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0262 - accuracy: 0.9860\n",
      "Epoch 75/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0259 - accuracy: 0.9874\n",
      "Epoch 76/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0259 - accuracy: 0.9872\n",
      "Epoch 77/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0274 - accuracy: 0.9859\n",
      "Epoch 78/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0258 - accuracy: 0.9872\n",
      "Epoch 79/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0276 - accuracy: 0.9874\n",
      "Epoch 80/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0274 - accuracy: 0.9862\n",
      "Epoch 81/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0270 - accuracy: 0.9864\n",
      "Epoch 82/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0261 - accuracy: 0.9880\n",
      "Epoch 83/128\n",
      "8844/8844 [==============================] - 0s 14us/step - loss: 0.0255 - accuracy: 0.9872\n",
      "Epoch 84/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0261 - accuracy: 0.9862\n",
      "Epoch 85/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0253 - accuracy: 0.9863\n",
      "Epoch 86/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0263 - accuracy: 0.9863\n",
      "Epoch 87/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0273 - accuracy: 0.9874\n",
      "Epoch 88/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0267 - accuracy: 0.9865\n",
      "Epoch 89/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0265 - accuracy: 0.9877\n",
      "Epoch 90/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0266 - accuracy: 0.9867\n",
      "Epoch 91/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0260 - accuracy: 0.9861\n",
      "Epoch 92/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0252 - accuracy: 0.9884\n",
      "Epoch 93/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0268 - accuracy: 0.9872\n",
      "Epoch 94/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0271 - accuracy: 0.9869\n",
      "Epoch 95/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0281 - accuracy: 0.9864\n",
      "Epoch 96/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0267 - accuracy: 0.9869\n",
      "Epoch 97/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0263 - accuracy: 0.9873\n",
      "Epoch 98/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0257 - accuracy: 0.9878\n",
      "Epoch 99/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0256 - accuracy: 0.9868\n",
      "Epoch 100/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0269 - accuracy: 0.9873\n",
      "Epoch 101/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0265 - accuracy: 0.9872\n",
      "Epoch 102/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0253 - accuracy: 0.9881\n",
      "Epoch 103/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0257 - accuracy: 0.9880\n",
      "Epoch 104/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0268 - accuracy: 0.9882\n",
      "Epoch 105/128\n",
      "8844/8844 [==============================] - 0s 14us/step - loss: 0.0254 - accuracy: 0.9882\n",
      "Epoch 106/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0266 - accuracy: 0.9867\n",
      "Epoch 107/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0268 - accuracy: 0.9865\n",
      "Epoch 108/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0262 - accuracy: 0.9873\n",
      "Epoch 109/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0245 - accuracy: 0.9869\n",
      "Epoch 110/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0262 - accuracy: 0.9874\n",
      "Epoch 111/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0281 - accuracy: 0.9870\n",
      "Epoch 112/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0262 - accuracy: 0.9881\n",
      "Epoch 113/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0274 - accuracy: 0.9864\n",
      "Epoch 114/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0281 - accuracy: 0.9861\n",
      "Epoch 115/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0260 - accuracy: 0.9872\n",
      "Epoch 116/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0259 - accuracy: 0.9872\n",
      "Epoch 117/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0258 - accuracy: 0.9871\n",
      "Epoch 118/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0286 - accuracy: 0.9862\n",
      "Epoch 119/128\n",
      "8844/8844 [==============================] - 0s 14us/step - loss: 0.0260 - accuracy: 0.9872\n",
      "Epoch 120/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0257 - accuracy: 0.9876\n",
      "Epoch 121/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0260 - accuracy: 0.9877\n",
      "Epoch 122/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0253 - accuracy: 0.9874\n",
      "Epoch 123/128\n",
      "8844/8844 [==============================] - 0s 14us/step - loss: 0.0254 - accuracy: 0.9873\n",
      "Epoch 124/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0244 - accuracy: 0.9880\n",
      "Epoch 125/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0253 - accuracy: 0.9874\n",
      "Epoch 126/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0265 - accuracy: 0.9868\n",
      "Epoch 127/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0254 - accuracy: 0.9873\n",
      "Epoch 128/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0256 - accuracy: 0.9882\n",
      "time to train: 17.689120054244995\n",
      "8844/8844 [==============================] - 0s 13us/step\n",
      "Accuracy: 98.86\n"
     ]
    }
   ],
   "source": [
    "# run all 128 epochs\n",
    "import time \n",
    "start  = time.time() \n",
    "duration = time.time() - start\n",
    "print(f'time to train: {duration}')\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=128, batch_size=64)\n",
    "duration = time.time() - start\n",
    "print(f'time to train: {duration}')\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,501\n",
      "Trainable params: 2,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es_cb = EarlyStopping(monitor=\"loss\", \n",
    "    patience=5, # number of epochs to consider\n",
    "    restore_best_weights=True, # restore the best weights when loss stops enhancing\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8844/8844 [==============================] - 0s 26us/step - loss: 0.3584 - accuracy: 0.8822\n",
      "Epoch 2/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1995 - accuracy: 0.9228\n",
      "Epoch 3/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1916 - accuracy: 0.9270\n",
      "Epoch 4/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1888 - accuracy: 0.9261\n",
      "Epoch 5/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1806 - accuracy: 0.9268\n",
      "Epoch 6/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1746 - accuracy: 0.9306\n",
      "Epoch 7/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1678 - accuracy: 0.9334\n",
      "Epoch 8/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1613 - accuracy: 0.9359\n",
      "Epoch 9/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1566 - accuracy: 0.9354\n",
      "Epoch 10/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1493 - accuracy: 0.9389\n",
      "Epoch 11/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1462 - accuracy: 0.9406\n",
      "Epoch 12/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1427 - accuracy: 0.9402\n",
      "Epoch 13/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1379 - accuracy: 0.9422\n",
      "Epoch 14/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1346 - accuracy: 0.9430\n",
      "Epoch 15/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1323 - accuracy: 0.9452\n",
      "Epoch 16/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1309 - accuracy: 0.9450\n",
      "Epoch 17/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.1263 - accuracy: 0.9465\n",
      "Epoch 18/128\n",
      "8844/8844 [==============================] - 0s 18us/step - loss: 0.1244 - accuracy: 0.9473\n",
      "Epoch 19/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1222 - accuracy: 0.9488\n",
      "Epoch 20/128\n",
      "8844/8844 [==============================] - 0s 19us/step - loss: 0.1216 - accuracy: 0.9456\n",
      "Epoch 21/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.1170 - accuracy: 0.9504\n",
      "Epoch 22/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1169 - accuracy: 0.9487\n",
      "Epoch 23/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1123 - accuracy: 0.9517\n",
      "Epoch 24/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1114 - accuracy: 0.9519\n",
      "Epoch 25/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1072 - accuracy: 0.9535\n",
      "Epoch 26/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1071 - accuracy: 0.9542\n",
      "Epoch 27/128\n",
      "8844/8844 [==============================] - 0s 18us/step - loss: 0.1055 - accuracy: 0.9545\n",
      "Epoch 28/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.1070 - accuracy: 0.9532\n",
      "Epoch 29/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.1041 - accuracy: 0.9560\n",
      "Epoch 30/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0998 - accuracy: 0.9568\n",
      "Epoch 31/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0998 - accuracy: 0.9565\n",
      "Epoch 32/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0967 - accuracy: 0.9590\n",
      "Epoch 33/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0961 - accuracy: 0.9588\n",
      "Epoch 34/128\n",
      "8844/8844 [==============================] - 0s 18us/step - loss: 0.0977 - accuracy: 0.9590\n",
      "Epoch 35/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0981 - accuracy: 0.9599\n",
      "Epoch 36/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0912 - accuracy: 0.9605\n",
      "Epoch 37/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0904 - accuracy: 0.9616\n",
      "Epoch 38/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0973 - accuracy: 0.9599\n",
      "Epoch 39/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0901 - accuracy: 0.9619\n",
      "Epoch 40/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0886 - accuracy: 0.9623\n",
      "Epoch 41/128\n",
      "8844/8844 [==============================] - 0s 20us/step - loss: 0.0895 - accuracy: 0.9608\n",
      "Epoch 42/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0850 - accuracy: 0.9643\n",
      "Epoch 43/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0861 - accuracy: 0.9651\n",
      "Epoch 44/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0826 - accuracy: 0.9659\n",
      "Epoch 45/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0842 - accuracy: 0.9633\n",
      "Epoch 46/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0826 - accuracy: 0.9651\n",
      "Epoch 47/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0808 - accuracy: 0.9657\n",
      "Epoch 48/128\n",
      "8844/8844 [==============================] - 0s 18us/step - loss: 0.0818 - accuracy: 0.9653\n",
      "Epoch 49/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0786 - accuracy: 0.9681\n",
      "Epoch 50/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0789 - accuracy: 0.9670\n",
      "Epoch 51/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0774 - accuracy: 0.9675\n",
      "Epoch 52/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0779 - accuracy: 0.9662\n",
      "Epoch 53/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0748 - accuracy: 0.9689\n",
      "Epoch 54/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0750 - accuracy: 0.9668\n",
      "Epoch 55/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0770 - accuracy: 0.9673\n",
      "Epoch 56/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0760 - accuracy: 0.9680\n",
      "Epoch 57/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0745 - accuracy: 0.9678\n",
      "Epoch 58/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0692 - accuracy: 0.9718\n",
      "Epoch 59/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0718 - accuracy: 0.9695\n",
      "Epoch 60/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0666 - accuracy: 0.9718\n",
      "Epoch 61/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0660 - accuracy: 0.9737\n",
      "Epoch 62/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0681 - accuracy: 0.9721\n",
      "Epoch 63/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0683 - accuracy: 0.9700\n",
      "Epoch 64/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0676 - accuracy: 0.9727\n",
      "Epoch 65/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0643 - accuracy: 0.9737\n",
      "Epoch 66/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0645 - accuracy: 0.9733\n",
      "Epoch 67/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0621 - accuracy: 0.9744\n",
      "Epoch 68/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0606 - accuracy: 0.9738\n",
      "Epoch 69/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0629 - accuracy: 0.9741\n",
      "Epoch 70/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0607 - accuracy: 0.9743\n",
      "Epoch 71/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0603 - accuracy: 0.9743\n",
      "Epoch 72/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0575 - accuracy: 0.9764\n",
      "Epoch 73/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0575 - accuracy: 0.9750\n",
      "Epoch 74/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0562 - accuracy: 0.9765\n",
      "Epoch 75/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0566 - accuracy: 0.9755\n",
      "Epoch 76/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0556 - accuracy: 0.9770\n",
      "Epoch 77/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0561 - accuracy: 0.9777\n",
      "Epoch 78/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0573 - accuracy: 0.9761\n",
      "Epoch 79/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0556 - accuracy: 0.9763\n",
      "Epoch 80/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0550 - accuracy: 0.9766\n",
      "Epoch 81/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0544 - accuracy: 0.9774\n",
      "Epoch 82/128\n",
      "8844/8844 [==============================] - 0s 18us/step - loss: 0.0530 - accuracy: 0.9765\n",
      "Epoch 83/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0525 - accuracy: 0.9763\n",
      "Epoch 84/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0494 - accuracy: 0.9780\n",
      "Epoch 85/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0526 - accuracy: 0.9765\n",
      "Epoch 86/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0509 - accuracy: 0.9774\n",
      "Epoch 87/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0500 - accuracy: 0.9783\n",
      "Epoch 88/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0509 - accuracy: 0.9790\n",
      "Epoch 89/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0484 - accuracy: 0.9803\n",
      "Epoch 90/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0492 - accuracy: 0.9782\n",
      "Epoch 91/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0490 - accuracy: 0.9786\n",
      "Epoch 92/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0474 - accuracy: 0.9800\n",
      "Epoch 93/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0503 - accuracy: 0.9781\n",
      "Epoch 94/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0463 - accuracy: 0.9792\n",
      "Epoch 95/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0464 - accuracy: 0.9806\n",
      "Epoch 96/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0486 - accuracy: 0.9793\n",
      "Epoch 97/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0465 - accuracy: 0.9817\n",
      "Epoch 98/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0464 - accuracy: 0.9806\n",
      "Epoch 99/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0490 - accuracy: 0.9789\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "time to train with ABS early stopping: 14.520589113235474\n",
      "8844/8844 [==============================] - 0s 15us/step\n",
      "Accuracy: 98.47\n"
     ]
    }
   ],
   "source": [
    "# try again with early stopping, skip the wandb for the moment\n",
    "model = get_training_model(X_train.shape[1])\n",
    "start  = time.time()  \n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=128, batch_size=64,callbacks=[es_cb])\n",
    "duration = time.time() - start\n",
    "print(f'time to train with ABS early stopping: {duration}')\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sayak's nifty little method\n",
    "from wandb.keras import WandbCallback\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "def train_network(model, name):\n",
    "    # Initialize Weights and Biases\n",
    "    wandb.init(project=\"phishing-websites-detection\", name=name)\n",
    "    \n",
    "    start = time.time()\n",
    "    history = model.fit(X_train, y_train, batch_size=64, epochs=128, verbose=1, \\\n",
    "        callbacks=[es_cb, WandbCallback()])\n",
    "    end = time.time()-start\n",
    "    prediction = model.predict_classes(X_test)\n",
    "    wandb.log({\"accuracy\":accuracy_score(y_test, prediction)*100.0,\\\n",
    "               \"precision\": precision_recall_fscore_support(y_test, prediction, average=\"macro\")[0],\n",
    "               \"recall\": precision_recall_fscore_support(y_test, prediction, average=\"macro\")[1],\n",
    "               \"training_time\":end})\n",
    "    print(\"Accuracy score of the Logistic Regression classifier with default hyperparameter values {0:.2f}%\"\\\n",
    "                  .format(accuracy_score(y_test, prediction)*100.))\n",
    "    print(\"\\n\")\n",
    "    print(\"----Classification report of the Logistic Regression classifier with default hyperparameter value----\")\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test, prediction, target_names=[\"Phishing Websites\", \"Normal Websites\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/credmond/phishing-websites-detection\" target=\"_blank\">https://app.wandb.ai/credmond/phishing-websites-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/credmond/phishing-websites-detection/runs/q1vc3t1a\" target=\"_blank\">https://app.wandb.ai/credmond/phishing-websites-detection/runs/q1vc3t1a</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8844/8844 [==============================] - 0s 22us/step - loss: 0.0503 - accuracy: 0.9778\n",
      "Epoch 2/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0452 - accuracy: 0.9810\n",
      "Epoch 3/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0461 - accuracy: 0.9801\n",
      "Epoch 4/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0440 - accuracy: 0.9812\n",
      "Epoch 5/128\n",
      "8844/8844 [==============================] - 0s 18us/step - loss: 0.0470 - accuracy: 0.9806\n",
      "Epoch 6/128\n",
      "8844/8844 [==============================] - 0s 17us/step - loss: 0.0457 - accuracy: 0.9798\n",
      "Epoch 7/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0437 - accuracy: 0.9809\n",
      "Epoch 8/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0427 - accuracy: 0.9818\n",
      "Epoch 9/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0417 - accuracy: 0.9816\n",
      "Epoch 10/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0444 - accuracy: 0.9809\n",
      "Epoch 11/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0459 - accuracy: 0.9806\n",
      "Epoch 12/128\n",
      "8844/8844 [==============================] - 0s 15us/step - loss: 0.0490 - accuracy: 0.9785\n",
      "Epoch 13/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0461 - accuracy: 0.9792\n",
      "Epoch 14/128\n",
      "8844/8844 [==============================] - 0s 16us/step - loss: 0.0431 - accuracy: 0.9815\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Accuracy score of the Logistic Regression classifier with default hyperparameter values 98.00%\n",
      "\n",
      "\n",
      "----Classification report of the Logistic Regression classifier with default hyperparameter value----\n",
      "\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Phishing Websites       1.00      0.96      0.98      3924\n",
      "  Normal Websites       0.97      1.00      0.98      4920\n",
      "\n",
      "         accuracy                           0.98      8844\n",
      "        macro avg       0.98      0.98      0.98      8844\n",
      "     weighted avg       0.98      0.98      0.98      8844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_network(model, \"neural-network\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
